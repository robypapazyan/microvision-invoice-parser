# -*- coding: utf-8 -*-
import os
import sys
import json
import re
import difflib

try:
    import pandas as pd

    PANDAS_AVAILABLE = True
except ImportError:
    pd = None  # type: ignore[assignment]
    PANDAS_AVAILABLE = False
    print("WARN: pandas –ª–∏–ø—Å–≤–∞ ‚Äì –ø—Ä–æ–¥—ä–ª–∂–∞–≤–∞–º–µ –±–µ–∑ —Ç–∞–±–ª–∏—Ü–∏ –æ—Ç materials.csv.")

def prompt_user(question, valid_answers=None, gui_mode=False):
    if gui_mode:
        import tkinter.simpledialog as simpledialog
        import tkinter.messagebox as messagebox
        import tkinter as tk
        root = tk.Tk()
        root.withdraw()

        while True:
            answer = simpledialog.askstring("–í—ä–ø—Ä–æ—Å", question)
            if answer is None:
                return "cancel"
            answer = answer.strip().lower()
            if valid_answers is None or answer in valid_answers:
                return answer
            else:
                messagebox.showwarning("–ù–µ–≤–∞–ª–∏–¥–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä", f"–ú–æ–ª—è, –æ—Ç–≥–æ–≤–æ—Ä–∏ —Å: {', '.join(valid_answers)}")
    else:
        while True:
            answer = input(question + " ").strip().lower()
            if valid_answers is None or answer in valid_answers:
                return answer
            else:
                print(f"–ù–µ–≤–∞–ª–∏–¥–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä. –ú–æ–ª—è, –≤—ä–≤–µ–¥–∏ –µ–¥–Ω–æ –æ—Ç: {', '.join(valid_answers)}")

# === –§–£–ù–ö–¶–ò–ò –ó–ê –û–ë–†–ê–ë–û–¢–ö–ê –ù–ê MAPPING ===
def normalize_line(line):
    line = re.sub(r"^\d+\s*", "", line)  # –ü—Ä–µ–º–∞—Ö–≤–∞ –≤–æ–¥–µ—â–∏ —á–∏—Å–ª–∞
    line = re.sub(r"\s*/.*", "", line)     # –ü—Ä–µ–º–∞—Ö–≤–∞ —Ç–µ–∫—Å—Ç —Å–ª–µ–¥ –Ω–∞–∫–ª–æ–Ω–µ–Ω–∞ —á–µ—Ä—Ç–∞
    return line.strip().lower()

def words_set(s):
    return set(re.findall(r'\b\w+\b', s.lower()))

def find_in_mapping(line, mapping):
    norm_line = normalize_line(line)
    line_words = words_set(norm_line)

    for key, value in mapping.items():
        key_words = words_set(key)
        if key_words.issubset(line_words) or line_words.issubset(key_words):
            return value['code'], key
    return None, None

def save_new_mapping(original_line, confirmed_code, mapping_file='mapping.json'):
    try:
        with open(mapping_file, 'r', encoding='utf-8') as f:
            mapping = json.load(f)
    except FileNotFoundError:
        mapping = {}

    cleaned_line = normalize_line(original_line)
    cleaned_line = re.sub(r'–±—Ä–æ—è.*', '', cleaned_line).strip()

    if cleaned_line not in mapping:
        mapping[cleaned_line] = {
            "code": confirmed_code,
                    }
        with open(mapping_file, 'w', encoding='utf-8') as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ –î–æ–±–∞–≤–µ–Ω –Ω–æ–≤ –∫–ª—é—á –≤ mapping: '{cleaned_line}' -> {confirmed_code}")
    else:
        print(f"‚ÑπÔ∏è –ö–ª—é—á—ä—Ç '{cleaned_line}' –≤–µ—á–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞ –≤ mapping.")

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
MAPPING_FILE = 'mapping.json'
MATERIALS_FILE = 'materials.csv'
EXPORT_DIR = 'export'
EXPORT_FILE = None  # –©–µ —Å–µ –æ–ø—Ä–µ–¥–µ–ª–∏ –¥–∏–Ω–∞–º–∏—á–Ω–æ –ø–æ-–∫—ä—Å–Ω–æ
FUZZY_MATCH_CUTOFF = 0.3 # –ü—Ä–∞–≥ –∑–∞ –±–ª–∏–∑–æ—Å—Ç –Ω–∞ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ (0.0 –¥–æ 1.0)

# --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–∞ –æ–ø—Ü–∏–æ–Ω–∞–ª–Ω–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ ---
# OCR support
try:
    from pdf2image import convert_from_path
    from PIL import Image, ImageEnhance, ImageFilter, ImageOps
    import pytesseract
    # –ê–∫–æ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è—Ç –Ω–µ –µ –∑–∞–¥–∞–ª –ø—ä—Ç—è –¥–æ Tesseract, –º–æ–∂–µ –¥–∞ —Å–µ –Ω–∞–ª–æ–∂–∏ –¥–∞ –≥–æ —É–∫–∞–∂–µ—Ç–µ —Ç—É–∫:
    # pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # –ü—Ä–∏–º–µ—Ä –∑–∞ Windows
    PYTESSERACT_AVAILABLE = True
    print("INFO: OCR —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç (Tesseract, pdf2image, PIL) –µ –Ω–∞–ª–∏—á–Ω–∞.")
except ImportError:
    PYTESSERACT_AVAILABLE = False
    print("WARN: OCR –±–∏–±–ª–∏–æ—Ç–µ–∫–∏—Ç–µ (pytesseract, pdf2image, Pillow) –Ω–µ —Å–∞ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω–∏. –û–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ –Ω–∞ —Å–∫–∞–Ω–∏—Ä–∞–Ω–∏ PDF/JPEG –Ω—è–º–∞ –¥–∞ —Ä–∞–±–æ—Ç–∏.")

OSD_ROTATE_RE = re.compile(r"Rotate:\s*(\d+)")

# PDF support
try:
    from PyPDF2 import PdfReader
    PYPDF2_AVAILABLE = True
except ImportError:
    print("ERROR: –ó–∞–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–∞—Ç–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ PyPDF2 –Ω–µ –µ –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–Ω–∞. –ú–æ–ª—è, –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–π—Ç–µ —è —Å 'pip install pypdf2'")
    sys.exit(1)

# --- –§—É–Ω–∫—Ü–∏–∏ ---

def _apply_exif_orientation(image):
    try:
        return ImageOps.exif_transpose(image)
    except Exception:
        return image


def _deskew_image(image):
    if not PYTESSERACT_AVAILABLE:
        return image
    try:
        osd_output = pytesseract.image_to_osd(image, config="--psm 0")
    except Exception:
        return image
    match = OSD_ROTATE_RE.search(osd_output or "")
    if not match:
        return image
    try:
        angle = int(match.group(1))
    except (ValueError, TypeError):
        return image
    angle = angle % 360
    if angle in (0, 360):
        return image
    try:
        return image.rotate(-angle, expand=True)
    except Exception:
        return image


def preprocess_image(image):
    """–ü–æ–¥–≥–æ—Ç–≤—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞ OCR."""
    try:
        working = _apply_exif_orientation(image)
        working = working.convert("L")
        working = ImageOps.autocontrast(working, cutoff=4)
        working = working.filter(ImageFilter.MedianFilter(size=3))
        working = _deskew_image(working)
        enhancer = ImageEnhance.Contrast(working)
        working = enhancer.enhance(1.4)
        threshold = working.point(lambda x: 0 if x < 135 else 255)
        return threshold
    except Exception as e:
        print(f"WARN: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")
        return image  # –í—ä—Ä–Ω–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–æ—Ç–æ –ø—Ä–∏ –≥—Ä–µ—à–∫–∞

def extract_text_from_pdf(pdf_path):
    """–ö–æ–º–±–∏–Ω–∏—Ä–∞–Ω–æ –∏–∑–≤–ª–∏—á–∞–Ω–µ: PyPDF2 + OCR fallback"""
    def has_meaningful_text(text: str) -> bool:
        cleaned = text.strip()
        if len(cleaned) < 40:
            return False
        letters = sum(1 for ch in cleaned if ch.isalpha())
        ratio = letters / len(cleaned)
        return ratio > 0.2

    text_pypdf2 = ""
    if PYPDF2_AVAILABLE:
        try:
            reader = PdfReader(pdf_path)
            text_pypdf2 = "\n".join((page.extract_text() or "") for page in reader.pages)
            print(f"INFO: PyPDF2 –∏–∑–≤–ª–µ—á–µ {len(text_pypdf2)} —Å–∏–º–≤–æ–ª–∞.")
        except Exception as exc:
            print(f"ERROR: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —á–µ—Ç–µ–Ω–µ –Ω–∞ PDF —Å PyPDF2: {exc}")
            text_pypdf2 = ""

    if text_pypdf2 and has_meaningful_text(text_pypdf2):
        return text_pypdf2

    print("‚ö†Ô∏è PyPDF2 –Ω–µ –≤—ä—Ä–Ω–∞ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ —Ç–µ–∫—Å—Ç. –ê–∫—Ç–∏–≤–∏—Ä–∞–º OCR fallback‚Ä¶")
    if not PYTESSERACT_AVAILABLE:
        print("ERROR: OCR —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç –Ω–µ –µ –Ω–∞–ª–∏—á–Ω–∞.")
        return text_pypdf2

    try:
        images = convert_from_path(pdf_path, dpi=300)
    except Exception as exc:
        print(f"ERROR: –ù–µ—É—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {exc}")
        return text_pypdf2

    ocr_text_parts = []
    for index, image in enumerate(images, start=1):
        print(f"INFO: OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {index}/{len(images)}‚Ä¶")
        processed = preprocess_image(image)
        try:
            part = pytesseract.image_to_string(
                processed,
                config=r"-l bul+eng --oem 3 --psm 6",
            )
        except Exception as exc:
            print(f"WARN: OCR –≥—Ä–µ—à–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {index}: {exc}")
            part = ""
        ocr_text_parts.append(part)

    ocr_text = "\n".join(ocr_text_parts)
    print(f"INFO: OCR –∏–∑–≤–ª–µ—á–µ {len(ocr_text)} —Å–∏–º–≤–æ–ª–∞.")
    return ocr_text or text_pypdf2

def ocr_image(image_obj):
    """–ò–∑–≤–ª–∏—á–∞ —Ç–µ–∫—Å—Ç –æ—Ç PIL Image –æ–±–µ–∫—Ç —Å OCR."""
    if not PYTESSERACT_AVAILABLE:
        print("WARN: OCR –Ω–µ –µ –Ω–∞–ª–∏—á–µ–Ω.")
        return ""
    try:
        processed_img = preprocess_image(image_obj.copy())
        # –ó–∞–¥–∞–π—Ç–µ –µ–∑–∏—Ü–∏ - –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏
        custom_config = r'-l bul+eng --oem 3 --psm 6'
        text = pytesseract.image_to_string(processed_img, config=custom_config)
        # print(f"DEBUG: OCR Raw Output:\n---\n{text}\n---") # –ó–∞ –æ—Ç—Å—Ç—Ä–∞–Ω—è–≤–∞–Ω–µ –Ω–∞ –≥—Ä–µ—à–∫–∏
        return text
    except Exception as e:
        print(f"ERROR: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ OCR –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {e}")
        # –ú–æ–∂–µ –¥–∞ –ø—Ä–æ–±–≤–∞—Ç–µ –±–µ–∑ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥ –ø—Ä–∏ –≥—Ä–µ—à–∫–∞
        try:
            print("INFO: –û–ø–∏—Ç –∑–∞ OCR –±–µ–∑ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥...")
            text = pytesseract.image_to_string(image_obj, lang='bul+eng')
            return text
        except Exception as e2:
             print(f"ERROR: –ü–æ–≤—Ç–æ—Ä–Ω–∞ OCR –≥—Ä–µ—à–∫–∞: {e2}")
             return ""

def extract_text_with_ocr(file_path):
    """–ò–∑–≤–ª–∏—á–∞ —Ç–µ–∫—Å—Ç –æ—Ç PDF (—á—Ä–µ–∑ OCR) –∏–ª–∏ JPEG —Ñ–∞–π–ª."""
    if not PYTESSERACT_AVAILABLE:
        print("ERROR: OCR —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç –Ω–µ –µ –Ω–∞–ª–∏—á–Ω–∞.")
        return ""

    text = ""
    try:
        if file_path.lower().endswith('.pdf'):
            return extract_text_from_pdf(file_path)
        if file_path.lower().endswith(('.jpg', '.jpeg', '.png', '.tiff', '.bmp')):
            print(f"INFO: OCR –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({os.path.basename(file_path)})‚Ä¶")
            with Image.open(file_path) as img:
                text = ocr_image(img)
        else:
            print(f"WARN: –ù–µ–ø–æ–¥–¥—ä—Ä–∂–∞–Ω —Ñ–∞–π–ª–æ–≤ —Ç–∏–ø –∑–∞ OCR: {file_path}")
            return ""

        print(f"INFO: –ò–∑–≤–ª–µ—á–µ–Ω —Ç–µ–∫—Å—Ç —á—Ä–µ–∑ OCR ({len(text)} —Å–∏–º–≤–æ–ª–∞).")
        return text

    except Exception as e:
        print(f"ERROR: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ OCR –µ–∫—Å—Ç—Ä–∞–∫—Ü–∏—è –æ—Ç {file_path}: {e}")
        return ""
def merge_broken_lines(lines):
    """–û–±–µ–¥–∏–Ω—è–≤–∞ —Ä–µ–¥–æ–≤–µ, –∫–æ–∏—Ç–æ –æ—á–µ–≤–∏–¥–Ω–æ —Å–∞ —á–∞—Å—Ç –æ—Ç –µ–¥–∏–Ω –ø—Ä–æ–¥—É–∫—Ç (–ø—Ä–∏–º–µ—Ä: –æ–ø–∏—Å–∞–Ω–∏–µ + —Å—Ç–æ–π–Ω–æ—Å—Ç–∏)."""
    merged = []
    skip_next = False

    for i in range(len(lines)):
        if skip_next:
            skip_next = False
            continue

        current = lines[i]
        next_line = lines[i+1] if i + 1 < len(lines) else ""

        # –ê–∫–æ —Ç–µ–∫—É—â–∏—è—Ç —Ä–µ–¥ –Ω—è–º–∞ —á–∏—Å–ª–∞, –∞ —Å–ª–µ–¥–≤–∞—â–∏—è—Ç –∏–º–∞ –ø–æ–Ω–µ 2 —á–∏—Å–ª–∞ —Å –¥–µ—Å–µ—Ç–∏—á–Ω–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ ‚Üí –æ–±–µ–¥–∏–Ω—è–≤–∞–º–µ
        if not re.search(r'\d', current) and len(re.findall(r'\d+[.,]\d{2}', next_line)) >= 2:
            combined = current.strip() + " " + next_line.strip()
            merged.append(combined)
            skip_next = True
        else:
            merged.append(current.strip())

    return merged

def is_product_line(line):
    """–ü—Ä–æ–≤–µ—Ä—è–≤–∞ –¥–∞–ª–∏ —Ä–µ–¥—ä—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ —Å—ä–¥—ä—Ä–∂–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞ –ø—Ä–æ–¥—É–∫—Ç."""
    line = line.strip()
    if not line:
        return False
    # 1. –¢—Ä—è–±–≤–∞ –¥–∞ –∏–º–∞ —Ü–∏—Ñ—Ä–∏
    if not re.search(r'\d', line):
        return False
    # 2. –¢—Ä—è–±–≤–∞ –¥–∞ –∏–º–∞ –ø–æ–Ω–µ 2 —á–∏—Å–ª–∞ –≤—ä–≤ —Ñ–æ—Ä–º–∞—Ç —Ü–µ–Ω–∞/—Å—Ç–æ–π–Ω–æ—Å—Ç (—Å ',' –∏–ª–∏ '.' –∏ 2 —Ü–∏—Ñ—Ä–∏)
    if len(re.findall(r'\b\d{1,10}[.,]\d{2}\b', line)) < 2:
         # –ê–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ —á–∏—Å–ª–æ + –º–µ—Ä–Ω–∞ –µ–¥–∏–Ω–∏—Ü–∞ (–Ω–∞–ø—Ä. "3 –±—Ä", "1.5 –∫–≥")
         if not re.search(r'\b\d+[\.,]?\d*\s*(?:–±—Ä|pcs|–∫–≥|kg|–ª|l|–º|m)\b', line, re.IGNORECASE):
             return False # –ê–∫–æ –Ω—è–º–∞ –Ω–∏—Ç–æ 2 —Ü–µ–Ω–∏, –Ω–∏—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å –µ–¥–∏–Ω–∏—Ü–∞ - –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–µ –µ –ø—Ä–æ–¥—É–∫—Ç
    # 3. –¢—Ä—è–±–≤–∞ –¥–∞ –∏–º–∞ –ø–æ–Ω–µ 3 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–∏ –±—É–∫–≤–∏ (–ö–∏—Ä–∏–ª–∏—Ü–∞ –∏–ª–∏ –õ–∞—Ç–∏–Ω–∏—Ü–∞)
    if not re.search(r'[\u0400-\u04FFa-zA-Z]{3,}', line):
        return False
    # 4. –ò–∑–±—è–≥–≤–∞–Ω–µ –Ω–∞ —Ä–µ–¥–æ–≤–µ —Å–∞–º–æ —Å –î–î–° –Ω–æ–º–µ—Ä, –¥–∞—Ç–∞, –∞–¥—Ä–µ—Å –∏ —Ç.–Ω. (–µ–≤—Ä–∏—Å—Ç–∏–∫–∞)
    if re.match(r'^(BG\s?)?\d{9,10}$', line): return False # –î–î–° –Ω–æ–º–µ—Ä
    if re.match(r'^\d{2}[./-]\d{2}[./-]\d{2,4}$', line): return False # –î–∞—Ç–∞
    if '–∞–¥—Ä–µ—Å' in line.lower() or '—Ç–µ–ª.' in line.lower() or 'e-mail' in line.lower(): return False
    if '–ú–û–õ' in line or 'IBAN' in line: return False
    if '–î–î–°' in line and len(re.findall(r'\d+[.,]\d{2}', line)) <= 2 : return False # –†–µ–¥–æ–≤–µ —Å–∞–º–æ —Å –î–î–° —Å—É–º–∏

    # –ê–∫–æ –≤—Å–∏—á–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–∏–Ω–∞—Ç:
    return True

def extract_quantity(line):
    """–û–ø–∏—Ç–≤–∞ –¥–∞ –∏–∑–≤–ª–µ—á–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ—Ç–æ –æ—Ç —Ä–µ–¥–∞ (–≤–µ—Ä—Å–∏—è 3)."""
    print(f"  DEBUG_QTY: –ê–Ω–∞–ª–∏–∑–∏—Ä–∞–º —Ä–µ–¥: '{line}'")
    # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª–Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞: –¥–æ–±–∞–≤–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –¥—É–º–∏ –∏ —á–∏—Å–ª–∞, –∞–∫–æ —Å–∞ —Å–ª–µ–ø–µ–Ω–∏
    line = re.sub(r'([–∞-—è–ê-–Øa-zA-Z]+)(\d+)', r'\1 \2', line)
    line = re.sub(r'(\d+)([–∞-—è–ê-–Øa-zA-Z]+)', r'\1 \2', line)
    numeric_values = []
    for n in re.findall(r'\d+[.,]?\d*', line):
        try:
            numeric_values.append(float(n.replace(',', '.')))
        except ValueError:
            continue



    # –ú–µ—Ç–æ–¥ 1: –¢—ä—Ä—Å–∏ —á–∏—Å–ª–æ + –º–µ—Ä–Ω–∞ –µ–¥–∏–Ω–∏—Ü–∞
    units_pattern = r'(–±—Ä|pcs|–±—Ä\.|–±—Ä–æ–π|–∫–≥|kg|–ª|l|–º|m|–∫-—Ç|–∫–æ–º|–æ–ø|–∫-—Ç–∞)\b' # –£–ª–∞–≤—è—â–∞ –≥—Ä—É–ø–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü–∞—Ç–∞
    match_unit = re.search(r'(\d+[\.,]?\d*)\s*(' + units_pattern + r')', line, re.IGNORECASE)

    # --- –ù–∞—á–∞–ª–æ –Ω–∞ –ª–æ–≥–∏–∫–∞—Ç–∞ –°–ê–ú–û –∞–∫–æ –ú–µ—Ç–æ–¥ 1 –Ω–∞–º–µ—Ä–∏ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ ---
    if match_unit:
        num_str_from_unit = match_unit.group(1) # –î–µ—Ñ–∏–Ω–∏—Ä–∞ —Å–µ –°–ê–ú–û —Ç—É–∫
        unit_found = match_unit.group(2)
        print(f"  DEBUG_QTY: –ú–µ—Ç–æ–¥ 1 –Ω–∞–º–µ—Ä–∏: –ß–∏—Å–ª–æ='{num_str_from_unit}', –ï–¥–∏–Ω–∏—Ü–∞='{unit_found}'")

        # –ü–†–û–í–ï–†–ö–ê: –î–∞–ª–∏ –Ω–∞–º–µ—Ä–µ–Ω–æ—Ç–æ —á–∏—Å–ª–æ –ø—Ä–∏–ª–∏—á–∞ –Ω–∞ —Ü–µ–Ω–∞? (—Å .,XX) - –¢–ê–ó–ò –ü–†–û–í–ï–†–ö–ê –ï –í–™–¢–†–ï –í if match_unit:
        if re.match(r'.*[.,]\d{2}$', num_str_from_unit):
            print(f"  DEBUG_QTY: –ß–∏—Å–ª–æ—Ç–æ '{num_str_from_unit}' –¥–æ –µ–¥–∏–Ω–∏—Ü–∞—Ç–∞ –ø—Ä–∏–ª–∏—á–∞ –Ω–∞ —Ü–µ–Ω–∞. –ò–≥–Ω–æ—Ä–∏—Ä–∞–º –∑–∞ –ú–µ—Ç–æ–¥ 1.")
            # –ù–µ –ø—Ä–∞–≤–∏–º –Ω–∏—â–æ, —â–µ —Å–µ –ø—Ä–æ–¥—ä–ª–∂–∏ –∫—ä–º –ú–µ—Ç–æ–¥ 2 –°–õ–ï–î else –±–ª–æ–∫–∞ –ø–æ-–¥–æ–ª—É
        else:
            # –ß–∏—Å–ª–æ—Ç–æ –ù–ï –ø—Ä–∏–ª–∏—á–∞ –Ω–∞ —Ü–µ–Ω–∞ - –≤–µ—Ä–æ—è—Ç–Ω–æ –µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            try:
                qty_str = num_str_from_unit.replace(',', '.')
                qty_float = float(qty_str)
                print(f"  DEBUG_QTY: –í—Ä—ä—â–∞–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç –ú–µ—Ç–æ–¥ 1: {qty_float}")
                return qty_float # –í—Ä—ä—â–∞–º–µ —Å–∞–º–æ –∞–∫–æ –ù–ï –ø—Ä–∏–ª–∏—á–∞ –Ω–∞ —Ü–µ–Ω–∞
            except ValueError:
                print(f"  DEBUG_QTY: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–Ω–µ –≤ –ú–µ—Ç–æ–¥ 1: {num_str_from_unit}")
                # –ü—Ä–æ–¥—ä–ª–∂–∞–≤–∞–º–µ –∫—ä–º –ú–µ—Ç–æ–¥ 2
    # --- –ö—Ä–∞–π –Ω–∞ –ª–æ–≥–∏–∫–∞—Ç–∞ –°–ê–ú–û –∞–∫–æ –ú–µ—Ç–æ–¥ 1 –Ω–∞–º–µ—Ä–∏ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ ---
    else: # –¢–æ–∑–∏ else –µ –∑–∞ 'if match_unit:'
        print(f"  DEBUG_QTY: –ú–µ—Ç–æ–¥ 1 (—á–∏—Å–ª–æ + –µ–¥–∏–Ω–∏—Ü–∞) –Ω–µ –Ω–∞–º–µ—Ä–∏ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ.")
        # –ü—Ä–æ–¥—ä–ª–∂–∞–≤–∞–º–µ –∫—ä–º –ú–µ—Ç–æ–¥ 2

    # --- –ú–µ—Ç–æ–¥ 2 –ó–ê–ü–û–ß–í–ê –¢–£–ö (–∏–∑–ø—ä–ª–Ω—è–≤–∞ —Å–µ —Å–∞–º–æ –∞–∫–æ –ú–µ—Ç–æ–¥ 1 –Ω–µ –µ –≤—ä—Ä–Ω–∞–ª —Å—Ç–æ–π–Ω–æ—Å—Ç) ---
    print(f"  DEBUG_QTY: –ò–∑–ø—ä–ª–Ω—è–≤–∞–º –ú–µ—Ç–æ–¥ 2 (–µ–≤—Ä–∏—Å—Ç–∏–∫–∏)...")
    price_values_matches = re.findall(r'\b(\d{1,10}[.,]\d{2})\b', line)
    likely_prices_set = {p.replace(',', '.') for p in price_values_matches}
    print(f"  DEBUG_QTY: –í–µ—Ä–æ—è—Ç–Ω–∏ —Ü–µ–Ω–∏/—Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–¥–∞: {likely_prices_set}")

    all_numbers_matches = list(re.finditer(r'\b(\d+[\.,]?\d*)\b', line))
    print(f"  DEBUG_QTY: –í—Å–∏—á–∫–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏ —á–∏—Å–ª–∞: {[m.group(1) for m in all_numbers_matches]}")

        # üö´ –ü–†–û–í–ï–†–ö–ê: –ü—ä—Ä–≤–æ—Ç–æ —á–∏—Å–ª–æ –≤ –Ω–∞—á–∞–ª–æ—Ç–æ –Ω–∞ —Ä–µ–¥–∞ –µ –ø–æ–¥ 100 –∏ –ø—Ä–µ–¥–∏ –ø—ä—Ä–≤–∞—Ç–∞ –¥—É–º–∞
    # –í–µ—Ä–æ—è—Ç–Ω–æ –µ –ø–æ—Ä–µ–¥–µ–Ω –Ω–æ–º–µ—Ä (–ø–æ–∑–∏—Ü–∏—è –≤—ä–≤ —Ñ–∞–∫—Ç—É—Ä–∞—Ç–∞), –ù–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    if all_numbers_matches:
        first_num_match = all_numbers_matches[0]
        first_num_str = first_num_match.group(1).replace(',', '.')
        try:
            first_num = float(first_num_str)
            if first_num.is_integer() and first_num < 100 and first_num_match.start() < 5:
                print(f"  DEBUG_QTY: '{first_num}' –∏–∑–≥–ª–µ–∂–¥–∞ –∫–∞—Ç–æ –ø–æ—Ä–µ–¥–µ–Ω –Ω–æ–º–µ—Ä ‚Äì —â–µ –≥–æ –∏–≥–Ω–æ—Ä–∏—Ä–∞–º–µ.")
                all_numbers_matches = all_numbers_matches[1:]  # –ü—Ä–µ–º–∞—Ö–≤–∞–º–µ –≥–æ –æ—Ç —Å–ø–∏—Å—ä–∫–∞
        except ValueError:
            pass


    potential_qty = []
    words = re.findall(r'[\u0400-\u04FFa-zA-Z]{3,}', line)
    first_word_index = line.find(words[0]) if words else len(line)
    print(f"  DEBUG_QTY: –ü—ä—Ä–≤–∞ –¥—É–º–∞ '{words[0] if words else 'N/A'}' –Ω–∞ –∏–Ω–¥–µ–∫—Å: {first_word_index}")

    for match in all_numbers_matches:
        num_str = match.group(1)
        num_val_str = num_str.replace(',', '.')
        num_index = match.start()
        is_likely_price = num_val_str in likely_prices_set
        is_before_first_word = (num_index < first_word_index)
        print(f"  DEBUG_QTY: –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º —á–∏—Å–ª–æ '{num_str}' –Ω–∞ –∏–Ω–¥–µ–∫—Å {num_index}. –ü—Ä–µ–¥–∏ –¥—É–º–∞: {is_before_first_word}. –í–µ—Ä–æ—è—Ç–Ω–∞ —Ü–µ–Ω–∞: {is_likely_price}")

        try:
            num_float = float(num_val_str)
        except ValueError:
            print(f"  DEBUG_QTY: –ù–µ –º–æ–≥–∞ –¥–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º '{num_str}' –≤ —á–∏—Å–ª–æ.")
            continue

        if is_likely_price:
            print(f"  DEBUG_QTY: –ü—Ä–æ–ø—É—Å–∫–∞–º '{num_str}' ‚Äì –∏–∑–≥–ª–µ–∂–¥–∞ –∫–∞—Ç–æ —Ü–µ–Ω–∞.")
            continue

        try:
            num_float = float(num_val_str)
        except ValueError:
            print(f"  DEBUG_QTY: –ù–µ –º–æ–≥–∞ –¥–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞–º '{num_str}' –≤ —á–∏—Å–ª–æ.")
            continue

        # ‚ö†Ô∏è –§–∏–ª—Ç—ä—Ä –∑–∞ 20.0 —Å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä –î–î–°)
        if num_float == 20.0:
            context_window = line[max(0, num_index - 10):num_index + 15].lower()
            if any(keyword in context_window for keyword in ['–¥–¥—Å', '–¥–∞–Ω—ä–∫', '—Å—É–º', '—Ü–µ–Ω–∞']):
                print(f"  DEBUG_QTY: ‚ùå –ò–≥–Ω–æ—Ä–∏—Ä–∞–º 20.0 ‚Äì —Å—ä—Å–µ–¥–µ–Ω —Ç–µ–∫—Å—Ç –∏–∑–≥–ª–µ–∂–¥–∞ –∫–∞—Ç–æ –î–î–°: '{context_window}'")
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–º–µ —Ç–æ–≤–∞ —á–∏—Å–ª–æ –∏–∑—Ü—è–ª–æ

        # ‚ûï –ê–∫–æ —á–∏—Å–ª–æ—Ç–æ –∏–∑–≥–ª–µ–∂–¥–∞ –≤–∞–ª–∏–¥–Ω–æ, –∏–∑—á–∏—Å–ª–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
            priority = 5
        if num_float == 1.0:
            priority = 0
            print(f"  DEBUG_QTY: -> –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 0 (—Ç–æ—á–Ω–æ 1.0)")
        elif is_before_first_word and '.' not in num_val_str and ',' not in num_val_str and num_float <= 100 and num_index < 5:
            priority = 1
            print(f"  DEBUG_QTY: -> –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1 (–º–∞–ª—ä–∫ int –≤ –Ω–∞—á–∞–ª–æ—Ç–æ)")
        elif is_before_first_word and '.' not in num_val_str and ',' not in num_val_str:
            priority = 2
            print(f"  DEBUG_QTY: -> –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2 (–¥—Ä—É–≥ int –ø—Ä–µ–¥–∏ –¥—É–º–∞)")
        elif is_before_first_word:
            priority = 3
            print(f"  DEBUG_QTY: -> –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3 (float –ø—Ä–µ–¥–∏ –¥—É–º–∞)")
        elif '.' not in num_val_str and ',' not in num_val_str:
            priority = 4
            print(f"  DEBUG_QTY: -> –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 4 (int —Å–ª–µ–¥ –¥—É–º–∞)")
        else:
            priority = 5
            print(f"  DEBUG_QTY: -> –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 5 (float —Å–ª–µ–¥ –¥—É–º–∞)")

        potential_qty.append({'value': num_float, 'priority': priority, 'index': num_index})


    if potential_qty:
         potential_qty.sort(key=lambda x: (x['priority'], x['index']))
         best_qty = potential_qty[0]['value']
         print(f"  DEBUG_QTY: –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª–Ω–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (—Å–æ—Ä—Ç–∏—Ä–∞–Ω–∏): {potential_qty}")
         print(f"  DEBUG_QTY: –ò–∑–±—Ä–∞–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {best_qty}")
         # –ü–æ—Å—Ç–∞–≤–∏ –ø—Ä–µ–¥–∏ return best_qty:
         for i in range(len(numeric_values) - 2):
             q, unit_price, total = numeric_values[i:i+3]
             if q > 0 and unit_price > 0:
                 calculated_total = round(q * unit_price, 2)
                 if abs(calculated_total - total) <= 0.01 * total:
                     print(f"‚úÖ DEBUG_QTY: –ú–µ—Ç–æ–¥ 2.6: –®–∞–±–ª–æ–Ω —Å—ä–≤–ø–∞–¥–∞: {q} * {unit_price} ‚âà {total}")
                     return q
         return best_qty
    
    
    # –ú–µ—Ç–æ–¥ 3: –ê–∫–æ –Ω–∏—â–æ –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ, –≤—Ä—ä—â–∞–º–µ 1.0
    print(f"WARN: –ù–µ—É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç —Ä–µ–¥ —á—Ä–µ–∑ –µ–≤—Ä–∏—Å—Ç–∏–∫–∏: '{line}'. –ü—Ä–∏–µ–º–∞ —Å–µ 1.0.")
    return 1.0
def load_materials_db():
    """–ó–∞—Ä–µ–∂–¥–∞ –±–∞–∑–∞—Ç–∞ –¥–∞–Ω–Ω–∏ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∏ –æ—Ç CSV —Ñ–∞–π–ª."""
    if not PANDAS_AVAILABLE:
        print("WARN: –ó–∞—Ä–µ–∂–¥–∞–Ω–µ—Ç–æ –Ω–∞ materials.csv –µ –ø—Ä–æ–ø—É—Å–Ω–∞—Ç–æ (pandas –ª–∏–ø—Å–≤–∞).")
        return None
    try:
        df = pd.read_csv(MATERIALS_FILE, sep=';', encoding='cp1251', dtype=str)
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–∞ –∑–∞–¥—ä–ª–∂–∏—Ç–µ–ª–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∏
        required_cols = ['–ù–æ–º–µ—Ä', '–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª', '–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞', '–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞', '–ë–∞—Ä–∫–æ–¥']
        if not all(col in df.columns for col in required_cols):
            missing = [col for col in required_cols if col not in df.columns]
            print(f"ERROR: –õ–∏–ø—Å–≤–∞—Ç –∫–æ–ª–æ–Ω–∏ –≤ '{MATERIALS_FILE}': {', '.join(missing)}")
            sys.exit(1)
        # –ò–∑—á–∏—Å—Ç–≤–∞–Ω–µ –Ω–∞ –ø—Ä–∞–∑–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –≤ –∫–ª—é—á–æ–≤–∏ –∫–æ–ª–æ–Ω–∏
        df = df.dropna(subset=['–ù–æ–º–µ—Ä', '–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª'])
        # –ü–æ–ø—ä–ª–≤–∞–Ω–µ –Ω–∞ –ø—Ä–∞–∑–Ω–∏ —Ü–µ–Ω–∏/–±–∞—Ä–∫–æ–¥ —Å '0' –∏–ª–∏ –ø—Ä–∞–∑–µ–Ω —Å—Ç—Ä–∏–Ω–≥
        df['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞'] = df['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞'].fillna('0.00')
        df['–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞'] = df['–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞'].fillna('0.00')
        df['–ë–∞—Ä–∫–æ–¥'] = df['–ë–∞—Ä–∫–æ–¥'].fillna('')
        print(f"INFO: –£—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–¥–µ–Ω–∏ {len(df)} –∑–∞–ø–∏—Å–∞ –æ—Ç '{MATERIALS_FILE}'.")
        return df[required_cols]
    except FileNotFoundError:
        print(f"\n‚ùå –§–∞–π–ª—ä—Ç —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∏ '{MATERIALS_FILE}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω!")
        print("–ú–æ–ª—è, –ø–æ—Å—Ç–∞–≤–∏ –≥–æ –≤ –ø–∞–ø–∫–∞—Ç–∞ –∏ –Ω–∞—Ç–∏—Å–Ω–∏ Enter, –∑–∞ –¥–∞ –æ–ø–∏—Ç–∞—à –æ—Ç–Ω–æ–≤–æ...")

        while True:
            input("‚û°Ô∏è –ù–∞—Ç–∏—Å–Ω–∏ Enter –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω –æ–ø–∏—Ç (–∏–ª–∏ –∑–∞—Ç–≤–æ—Ä–∏ –ø—Ä–æ–∑–æ—Ä–µ—Ü–∞ –∑–∞ –æ—Ç–∫–∞–∑): ")
            if os.path.exists(MATERIALS_FILE):
                return load_materials_db()  # –ü–æ–≤—Ç–æ—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ—Ç–æ
            else:
                print(f"‚õîÔ∏è –§–∞–π–ª—ä—Ç '{MATERIALS_FILE}' –≤—Å–µ –æ—â–µ –ª–∏–ø—Å–≤–∞.")

def load_mapping():
    """–ó–∞—Ä–µ–∂–¥–∞ JSON —Ñ–∞–π–ª–∞ —Å –∞—Å–æ—Ü–∏–∞—Ü–∏–∏."""
    if os.path.exists(MAPPING_FILE):
        try:
            with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
                mapping_data = json.load(f)
                print(f"INFO: –£—Å–ø–µ—à–Ω–æ –∑–∞—Ä–µ–¥–µ–Ω–∏ {len(mapping_data)} –∞—Å–æ—Ü–∏–∞—Ü–∏–∏ –æ—Ç '{MAPPING_FILE}'.")
                return mapping_data
        except json.JSONDecodeError:
            print(f"ERROR: –§–∞–π–ª—ä—Ç '{MAPPING_FILE}' –µ –ø–æ–≤—Ä–µ–¥–µ–Ω (–Ω–µ–≤–∞–ª–∏–¥–µ–Ω JSON). –©–µ –±—ä–¥–µ —Å—ä–∑–¥–∞–¥–µ–Ω –Ω–æ–≤.")
            return {}
        except Exception as e:
            print(f"ERROR: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ '{MAPPING_FILE}': {e}")
            return {} # –í—ä—Ä–Ω–∏ –ø—Ä–∞–∑–µ–Ω —Ä–µ—á–Ω–∏–∫ –ø—Ä–∏ –¥—Ä—É–≥–∞ –≥—Ä–µ—à–∫–∞
    else:
        print(f"INFO: –§–∞–π–ª—ä—Ç '{MAPPING_FILE}' –Ω–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞. –©–µ –±—ä–¥–µ —Å—ä–∑–¥–∞–¥–µ–Ω –ø—Ä–∏ –ø—ä—Ä–≤–æ—Ç–æ –∑–∞–ø–∞–∑–≤–∞–Ω–µ.")
        return {}

def save_mapping(mapping):
    """–ó–∞–ø–∞–∑–≤–∞ JSON —Ñ–∞–π–ª–∞ —Å –∞—Å–æ—Ü–∏–∞—Ü–∏–∏."""
    try:
        with open(MAPPING_FILE, 'w', encoding='utf-8') as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2, sort_keys=True)
        print(f"INFO: –ê—Å–æ—Ü–∏–∞—Ü–∏–∏—Ç–µ —Å–∞ –∑–∞–ø–∞–∑–µ–Ω–∏ –≤ '{MAPPING_FILE}'.")
    except Exception as e:
        print(f"ERROR: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ '{MAPPING_FILE}': {e}")

def export_to_mistral_format(items, export_path):
    """–ï–∫—Å–ø–æ—Ä—Ç–∏—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–µ–Ω–∏—Ç–µ –∞—Ä—Ç–∏–∫—É–ª–∏ –≤ TXT —Ñ–æ—Ä–º–∞—Ç –∑–∞ –ú–∏—Å—Ç—Ä–∞–ª."""
    try:
        with open(export_path, 'w', encoding='cp1251') as f:
            # Header - –í–∞–∂–Ω–æ –µ –¥–∞ –µ —Ç–æ—á–Ω–æ —Ç–∞–∫–∞!
            f.write("–°–∫–ª–∞–¥\t–°–∫–ª–∞–¥\t–ù–æ–º–µ—Ä\t–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª\t–ö-–≤–æ\t–ï–¥. —Ü–µ–Ω–∞\t–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞\t–ë–∞—Ä–∫–æ–¥\n")
            for item in items:
                # –§–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω–µ –Ω–∞ —á–∏—Å–ª–∞—Ç–∞ —Å —Ç–æ—á–∫–∞ –∫–∞—Ç–æ –¥–µ—Å–µ—Ç–∏—á–µ–Ω —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª
                qty_str = str(item['qty']) # –í–µ—á–µ —Ç—Ä—è–±–≤–∞ –¥–∞ –µ float
                unit_price_str = str(item['purchase_price']).replace(',', '.') # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–∞–º–µ —Ç–æ—á–∫–∞
                selling_price_str = str(item['selling_price']).replace(',', '.') # –ì–∞—Ä–∞–Ω—Ç–∏—Ä–∞–º–µ —Ç–æ—á–∫–∞

                # –ó–∞–ø–∏—Å –Ω–∞ —Ä–µ–¥–∞ —Å TAB —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
                f.write(f"1.00\t–°–∫–ª–∞–¥\t{item['code']}\t{item['name']}\t"
                        f"{qty_str}\t{unit_price_str}\t"
                        f"{selling_price_str}\t{item['barcode']}\n")
        print(f"\n‚úÖ –ï–∫—Å–ø–æ—Ä—Ç—ä—Ç ({len(items)} –∞—Ä—Ç–∏–∫—É–ª–∞) –µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω –≤: {EXPORT_FILE}\n")
    except Exception as e:
        print(f"ERROR: –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –µ–∫—Å–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –≤ '{EXPORT_FILE}': {e}")

# --- –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥–∏–∫–∞ ---
print("DEBUG: –°—Ç–∏–≥–Ω–∞—Ö –¥–æ –¥–µ—Ñ–∏–Ω–∏—Ü–∏—è—Ç–∞ –Ω–∞ main()")
def main(input_path=None, gui_mode=False):
    print("DEBUG: –í–ª—è–∑–æ—Ö –≤ main()")
    if input_path is None:
        input_path = input_path = prompt_user("–í—ä–≤–µ–¥–∏ –ø—ä–ª–Ω–∏—è –ø—ä—Ç –¥–æ PDF –∏–ª–∏ JPEG —Ñ–∞–π–ª–∞:", gui_mode=gui_mode)
    else:
        print(f"INFO: –ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª –æ—Ç GUI: {input_path}")

    if not os.path.exists(input_path):
        print(f"‚ùå –ì—Ä–µ—à–∫–∞: –§–∞–π–ª—ä—Ç '{input_path}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω!")
        return

    # ... –ø—Ä–æ–¥—ä–ª–∂–∞–≤–∞ –ª–æ–≥–∏–∫–∞—Ç–∞ ...
    # üÜï –ò–ó–í–õ–ò–ß–ê–ù–ï –ù–ê –ò–ú–ï–¢–û –ù–ê –§–ê–ô–õ–ê –ò –°–™–ó–î–ê–í–ê–ù–ï –ù–ê –ü–ê–ü–ö–ê export/
    invoice_filename = os.path.splitext(os.path.basename(input_path))[0]

    if not os.path.exists(EXPORT_DIR):
        os.makedirs(EXPORT_DIR)
        print(f"INFO: –°—ä–∑–¥–∞–¥–µ–Ω–∞ –µ –ø–∞–ø–∫–∞ –∑–∞ –µ–∫—Å–ø–æ—Ä—Ç–∏: {EXPORT_DIR}")

    export_path = os.path.join(EXPORT_DIR, f"export_{invoice_filename}.txt")

    if not os.path.exists(input_path):
        print(f"‚ùå –ì—Ä–µ—à–∫–∞: –§–∞–π–ª—ä—Ç '{input_path}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω!")
        return

    # 2. –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏
    materials_df = load_materials_db() if PANDAS_AVAILABLE else None
    mapping = load_mapping()
    export_items = []
    processed_lines_count = 0
    skipped_lines_count = 0
    matched_via_mapping = 0
    matched_via_fuzzy = 0
    matched_via_manual = 0
    failed_match_count = 0

    # 3. –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç
    text = ""
    file_ext = os.path.splitext(input_path)[1].lower()

    if file_ext == '.pdf':
        text = extract_text_from_pdf(input_path)

    elif file_ext in ('.jpg', '.jpeg', '.png', '.tiff', '.bmp'):
        if PYTESSERACT_AVAILABLE:
            text = extract_text_with_ocr(input_path)
        else:
            print("ERROR: OCR –Ω–µ –µ –Ω–∞–ª–∏—á–µ–Ω –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
            return

    else:
        print(f"‚ùå –ì—Ä–µ—à–∫–∞: –ù–µ–ø–æ–¥–¥—ä—Ä–∂–∞–Ω —Ñ–∞–π–ª–æ–≤ —Ñ–æ—Ä–º–∞—Ç '{file_ext}'. –ü–æ–¥–¥—ä—Ä–∂–∞—Ç —Å–µ PDF, JPG, JPEG, PNG, TIFF, BMP.")
        return

    # —Ç–∞–∑–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—á–µ –µ —Å–ª–µ–¥ –≤—Å–∏—á–∫–æ
    if not text or not text.strip():
        print("‚ùå –ì—Ä–µ—à–∫–∞: –ù–µ—É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ —Ç–µ–∫—Å—Ç –æ—Ç —Ñ–∞–π–ª–∞.")
        return


    lines = [line.strip() for line in text.split('\n') if line.strip()]
    print(f"\n--- –ò–∑–≤–ª–µ—á–µ–Ω–∏ {len(lines)} —Ä–µ–¥–∞ –æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ ---")

    # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Ä–µ–¥–æ–≤–µ—Ç–µ
    needs_saving = False # –§–ª–∞–≥ –¥–∞–ª–∏ –∏–º–∞ –ø—Ä–æ–º—è–Ω–∞ –≤ mapping.json
    if materials_df is not None:
        material_names_list = materials_df['–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª'].tolist() # –ó–∞ –ø–æ-–±—ä—Ä–∑–æ —Ç—ä—Ä—Å–µ–Ω–µ
    else:
        material_names_list = []
        print("WARN: –ù—è–º–∞ –∑–∞—Ä–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∏ ‚Äì –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏—Ç–µ —Å—ä–≤–ø–∞–¥–µ–Ω–∏—è —Å–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏.")

    for i, line in enumerate(lines):
        print(f"\n[–†–µ–¥ {i+1}/{len(lines)}] –û–±—Ä–∞–±–æ—Ç–≤–∞–º: '{line}'")
        if not is_product_line(line):
            print("  -> –ü—Ä–æ–ø—É—Å–∫–∞–º (–Ω–µ –∏–∑–≥–ª–µ–∂–¥–∞ –∫–∞—Ç–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Ä–µ–¥).")
            skipped_lines_count += 1
            continue

        processed_lines_count += 1
        found = False
        item_data = None

        only_name = normalize_line(line)
        # --- –ù–ê–ß–ê–õ–û –ù–ê –ö–û–†–ï–ö–¶–ò–Ø–¢–ê ---
        # –¢–µ–∑–∏ –¥–≤–∞ —Ä–µ–¥–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–∞ –ü–†–ï–î–ò —Ü–∏–∫—ä–ª–∞ for key in mapping:
        line_lower = line.lower()
        # –í–∑–∏–º–∞–º–µ –≤—Å–∏—á–∫–∏ –¥—É–º–∏ (–±—É–∫–≤–∏/—Ü–∏—Ñ—Ä–∏/—Ç–∏—Ä–µ—Ç–∞) –æ—Ç —Ä–µ–¥–∞ –≤–µ–¥–Ω—ä–∂
        line_words = set(re.findall(r'\b[\w\u0400-\u04FF-]+\b', only_name))
        cleaned_line = normalize_line(line)  # –ò–∑—á–∏—Å—Ç–µ–Ω —Ä–µ–¥ –∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å mapping

        # 4.1 –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ mapping.json
        
        print(f"  DEBUG_MAP: –ü—Ä–æ–≤–µ—Ä—è–≤–∞–º —Ä–µ–¥: '{line}'")
        # –¢–æ–∑–∏ print –≤–µ—á–µ —â–µ —Ä–∞–±–æ—Ç–∏, –∑–∞—â–æ—Ç–æ line_words –µ –¥–µ—Ñ–∏–Ω–∏—Ä–∞–Ω –ø–æ-–≥–æ—Ä–µ:
        print(f"  DEBUG_MAP: –î—É–º–∏ –≤ —Ä–µ–¥: {line_words}")
        for key in mapping:
            key_lower = key.lower()
            # –í–∑–∏–º–∞–º–µ –≤—Å–∏—á–∫–∏ –¥—É–º–∏ –æ—Ç –∫–ª—é—á–∞ (–≤–∫–ª—é—á–∏—Ç–µ–ª–Ω–æ —Ç–µ–∑–∏ —Å —Ç–∏—Ä–µ—Ç–∞)
            key_words = set(re.findall(r'\b[\w\u0400-\u04FF-]+\b', key_lower))

            # –ü—Ä–æ–≤–µ—Ä–∫–∞: –î–∞–ª–∏ –∫–ª—é—á—ä—Ç –∏–º–∞ –¥—É–º–∏ –ò –¥–∞–ª–∏ –≤—Å–∏—á–∫–∏ –¥—É–º–∏ –æ—Ç –∫–ª—é—á–∞ —Å–µ —Å—ä–¥—ä—Ä–∂–∞—Ç –≤ –¥—É–º–∏—Ç–µ –æ—Ç —Ä–µ–¥–∞?
            match_found = bool(key_words and key_words.issubset(line_words))
            print(f"  DEBUG_MAP: –°—Ä–∞–≤–Ω—è–≤–∞–º –î–£–ú–ò –æ—Ç –∫–ª—é—á '{key}' (-> {key_words}) —Å –î–£–ú–ò –æ—Ç —Ä–µ–¥ -> –†–µ–∑—É–ª—Ç–∞—Ç: {match_found}")

            if match_found:
                data = mapping[key]
                if materials_df is None:
                    print("  ‚ö†Ô∏è materials.csv –Ω–µ –µ –∑–∞—Ä–µ–¥–µ–Ω ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–º mapping –∑–∞ —Ç–æ–∑–∏ —Ä–µ–¥.")
                    failed_match_count += 1
                    found = True
                    break
                # –ù–∞–º–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–µ–¥–∞ –≤ –±–∞–∑–∞—Ç–∞ –¥–∞–Ω–Ω–∏
                row = materials_df[materials_df['–ù–æ–º–µ—Ä'] == data['code']]
                if not row.empty:
                    row_data = row.iloc[0]
                    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ item_data, –∏–∑–≤–∏–∫–≤–∞–Ω–µ –Ω–∞ extract_quantity –∏ —Ç.–Ω.
                    item_data = {
                        'code': row_data['–ù–æ–º–µ—Ä'],
                        'name': row_data['–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª'], # –í–∏–Ω–∞–≥–∏ –∏–º–µ—Ç–æ –æ—Ç –±–∞–∑–∞—Ç–∞
                        'qty': extract_quantity(line),      # –ò–∑–≤–ª–∏—á–∞–º–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ—Ç–æ –í–ò–ù–ê–ì–ò
                        'purchase_price': row_data['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'selling_price': row_data['–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'barcode': row_data['–ë–∞—Ä–∫–æ–¥'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'token': line,
                    }
                    print(f"  ‚úÖ –ù–∞–º–µ—Ä–µ–Ω–æ –≤ mapping —á—Ä–µ–∑ –°–™–í–ü–ê–î–ï–ù–ò–ï –ù–ê –î–£–ú–ò: '{key}' -> {item_data['code']} / {item_data['name']}")
                    export_items.append(item_data)
                    matched_via_mapping += 1
                    found = True # –ú–∞—Ä–∫–∏—Ä–∞–º–µ, —á–µ –µ –Ω–∞–º–µ—Ä–µ–Ω
                    break # –ò–∑–ª–∏–∑–∞–º–µ –æ—Ç —Ü–∏–∫—ä–ª–∞ for key in mapping
                else:
                    print(f"  ‚ö†Ô∏è –ù–∞–º–µ—Ä–µ–Ω –∫–ª—é—á '{key}' –≤ mapping (–ø–æ –¥—É–º–∏), –Ω–æ –∫–æ–¥ '{data['code']}' –Ω–µ –µ –æ—Ç–∫—Ä–∏—Ç –≤ materials.csv! –ü—Ä–æ–ø—É—Å–∫–∞–º.")
                    failed_match_count +=1
                    found = True # –ú–∞—Ä–∫–∏—Ä–∞–º–µ –∫–∞—Ç–æ –æ–±—Ä–∞–±–æ—Ç–µ–Ω (–º–∞–∫–∞—Ä –∏ –≥—Ä–µ—à–Ω–æ), –∑–∞ –¥–∞ –Ω–µ —Ç—ä—Ä—Å–∏ fuzzy
                    break # –ò–∑–ª–∏–∑–∞–º–µ –æ—Ç —Ü–∏–∫—ä–ª–∞ for key in mapping
        # --- –ö—Ä–∞–π –Ω–∞ mapping –ø—Ä–æ–≤–µ—Ä–∫–∞—Ç–∞ ---

        # –¢–æ–∑–∏ if –±–ª–æ–∫ —Å–∏ –æ—Å—Ç–∞–≤–∞ –°–õ–ï–î —Ü–∏–∫—ä–ª–∞ for key in mapping:
        if found:
            # –ê–∫–æ –µ –Ω–∞–º–µ—Ä–µ–Ω —á—Ä–µ–∑ mapping –ò–õ–ò –µ –≤—ä–∑–Ω–∏–∫–Ω–∞–ª –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∞ –≤ mapping (found=True),
            # –ø—Ä–æ–ø—É—Å–Ω–∏ fuzzy matching –∏ –º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥ –æ—Ç —Ñ–∞–∫—Ç—É—Ä–∞—Ç–∞
            continue
        # --- –ö–†–ê–ô –ù–ê –ö–û–†–ï–ö–¶–ò–Ø–¢–ê ---

        # –ê–∫–æ –ù–ï –µ –Ω–∞–º–µ—Ä–µ–Ω –≤ mapping (found –æ—Å—Ç–∞–≤–∞ False):
        # –õ–æ–≥–∏–∫–∞—Ç–∞ –∑–∞ fuzzy matching –∑–∞–ø–æ—á–≤–∞ –æ—Ç —Ç—É–∫ (—Ä–µ–¥ ~422 –∏ –Ω–∞–¥–æ–ª—É)
        print("  -> –ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω –≤ mapping. –¢—ä—Ä—Å—è –±–ª–∏–∑–∫–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ...")
        # –£–≤–µ—Ä–∏ —Å–µ, —á–µ —Ç–æ–∑–∏ —Ä–µ–¥ –µ —Ç—É–∫ –∏ –Ω–µ –µ –∫–æ–º–µ–Ω—Ç–∞—Ä:
        closest_matches = difflib.get_close_matches(line, material_names_list, n=1, cutoff=FUZZY_MATCH_CUTOFF)
        if closest_matches:
             # ... –∏ —Ç.–Ω. ...
             if found:
            # –ê–∫–æ –µ –Ω–∞–º–µ—Ä–µ–Ω —á—Ä–µ–∑ mapping –ò–õ–ò –µ –≤—ä–∑–Ω–∏–∫–Ω–∞–ª –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∞ –≤ mapping (found=True),
            # –ø—Ä–æ–ø—É—Å–Ω–∏ fuzzy matching –∏ –º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥ –æ—Ç —Ñ–∞–∫—Ç—É—Ä–∞—Ç–∞
                   continue



        # 4.2 –¢—ä—Ä—Å–µ–Ω–µ —á—Ä–µ–∑ Fuzzy Matching (–∞–∫–æ –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω –≤ mapping)
        print("  -> –ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω –≤ mapping. –¢—ä—Ä—Å—è –±–ª–∏–∑–∫–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ...")
        closest_matches = difflib.get_close_matches(line, material_names_list, n=1, cutoff=FUZZY_MATCH_CUTOFF)

        if closest_matches:
            if materials_df is None:
                print("  ‚ö†Ô∏è –ù—è–º–∞ –∑–∞—Ä–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∏ ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–º fuzzy —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ—Ç–æ.")
                failed_match_count += 1
                continue
            matched_name = closest_matches[0]
            matched_row = materials_df[materials_df['–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª'] == matched_name]
            if matched_row.empty:
                print("  ‚ö†Ô∏è –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–æ—Ç–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ –≤ materials.csv ‚Äì –ø—Ä–æ–ø—É—Å–∫–∞–º.")
                failed_match_count += 1
                continue
            matched_row = matched_row.iloc[0]

            print(f"\n‚ùì –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª–Ω–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ –∑–∞ —Ä–µ–¥: '{line}'")
            print(f"   -> –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç –±–∞–∑–∞—Ç–∞: {matched_row['–ù–æ–º–µ—Ä']} ‚Äì {matched_name} (–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞: {matched_row['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞']})")

            while True:
                answer = prompt_user(
                    f"–†–µ–¥:\n'{line}'\n\n–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç –±–∞–∑–∞—Ç–∞:\n{matched_row['–ù–æ–º–µ—Ä']} ‚Äì {matched_name}\n\n–ü–æ—Ç–≤—ä—Ä–∂–¥–∞–≤–∞—à –ª–∏?\n(–≤—ä–≤–µ–¥–∏: y = –¥–∞ / n = –Ω–µ / s = –ø—Ä–æ–ø—É—Å–Ω–∏)",
                    ['y', 'n', 's'],
                    gui_mode=gui_mode
                )
                if answer == 'cancel':
                    print("‚ùå –ü—Ä–µ–∫—ä—Å–Ω–∞—Ç–æ –æ—Ç –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è. –ü—Ä–æ–ø—É—Å–∫–∞–º —Ä–µ–¥–∞.")
                    failed_match_count += 1
                    break
                elif answer in ['y', 'yes', '–¥', '–¥–∞']:
                    # –ü–æ—Ç–≤—ä—Ä–¥–µ–Ω–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ
                    ...
                    # –ü–æ—Ç–≤—ä—Ä–¥–µ–Ω–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ
                    item_data = {
                        'code': matched_row['–ù–æ–º–µ—Ä'],
                        'name': matched_name, # –ò–º–µ—Ç–æ –æ—Ç –±–∞–∑–∞—Ç–∞
                        'qty': extract_quantity(line),
                        'purchase_price': matched_row['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'selling_price': matched_row['–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'barcode': matched_row['–ë–∞—Ä–∫–æ–¥'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'token': line,
                    } # <--- –£–í–ï–†–ò –°–ï, –ß–ï –¢–ê–ó–ò –°–ö–û–ë–ê –ï –¢–£–ö!
                    export_items.append(item_data)
                    save_new_mapping(line, matched_row['–ù–æ–º–µ—Ä'])  # <-- —Ç–æ–∑–∏ —Ä–µ–¥ –¥–æ–±–∞–≤–∏ –¢–£–ö
                    matched_via_fuzzy += 1
                    break # –ü—Ä–µ–º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥
                    # –ì–æ—Ä–Ω–∏—è—Ç –∫–æ–¥ –ø—Ä–∏ —Ç–µ–± —Å–≤—ä—Ä—à–≤–∞ —Å break –Ω–∞ —Ä–µ–¥ 393
                elif answer in ['n', 'no', '–Ω', '–Ω–µ']:
                    # –û—Ç—Ö–≤—ä—Ä–ª–µ–Ω–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ - –ø–∏—Ç–∞–π –∑–∞ —Ä—ä—á–µ–Ω –∫–æ–¥
                    manual_code = prompt_user("–í—ä–≤–µ–¥–∏ –ø—Ä–∞–≤–∏–ª–Ω–∏—è –∫–æ–¥ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ (–æ—Å—Ç–∞–≤–∏ –ø—Ä–∞–∑–Ω–æ –∑–∞ –ø—Ä–æ–ø—É—Å–∫–∞–Ω–µ):", None, gui_mode=gui_mode)
                    if not manual_code:
                        print("  -> –ü—Ä–æ–ø—É—Å–∫–∞–º —Ç–æ–∑–∏ —Ä–µ–¥ –ø–æ –∂–µ–ª–∞–Ω–∏–µ –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è.")
                        failed_match_count +=1
                        break # –ü—Ä–µ–º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥

                    result = materials_df[materials_df['–ù–æ–º–µ—Ä'] == manual_code]
                    if not result.empty:
                        row_data = result.iloc[0]
                        manual_matched_name = row_data['–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª']
                        item_data = {
                            'code': manual_code,
                            'name': manual_matched_name, # –ò–º–µ—Ç–æ –æ—Ç –±–∞–∑–∞—Ç–∞
                            'qty': extract_quantity(line),
                            'purchase_price': row_data['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                            'selling_price': row_data['–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                            'barcode': row_data['–ë–∞—Ä–∫–æ–¥'], # –û—Ç –±–∞–∑–∞—Ç–∞
                            'token': line,
                        } # <--- –£–í–ï–†–ò –°–ï, –ß–ï –ò –¢–£–ö –ò–ú–ê –°–ö–û–ë–ê!
                        export_items.append(item_data)
                         # –î–æ–±–∞–≤—è–Ω–µ –∫—ä–º mapping —Å –ò–ú–ï–¢–û –û–¢ –ë–ê–ó–ê–¢–ê –∫–∞—Ç–æ –∫–ª—é—á
                        cleaned_line = normalize_line(line)
                        mapping[cleaned_line] = {
                            'code': manual_code,
                            'name': manual_matched_name  # —Ç–æ–≤–∞ –æ—Å—Ç–∞–≤–∞ –∏–º–µ—Ç–æ –æ—Ç –±–∞–∑–∞—Ç–∞
                        }
                        needs_saving = True # –ú–∞—Ä–∫–∏—Ä–∞–º–µ –∑–∞ –∑–∞–ø–∏—Å
                        print(f"  ‚úÖ –†—ä—á–Ω–æ –≤—ä–≤–µ–¥–µ–Ω –∫–æ–¥ '{manual_code}' ({manual_matched_name}). –î–æ–±–∞–≤—è–º –∫—ä–º –µ–∫—Å–ø–æ—Ä—Ç –∏ –∑–∞–ø–∏—Å–≤–∞–º –≤ mapping.")
                        matched_via_manual += 1
                        break # –ü—Ä–µ–º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥
                    else:
                        print(f"  ‚ùå –ì—Ä–µ—à–∫–∞: –ö–æ–¥ '{manual_code}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω –≤ '{MATERIALS_FILE}'. –û–ø–∏—Ç–∞–π –ø–∞–∫.")
                        # –¶–∏–∫—ä–ª—ä—Ç —â–µ –ø–æ–ø–∏—Ç–∞ –æ—Ç–Ω–æ–≤–æ –∑–∞ Y/n/s
                elif answer in ['s', 'skip']:
                     print("  -> –ü—Ä–æ–ø—É—Å–∫–∞–º —Ç–æ–∑–∏ —Ä–µ–¥ –ø–æ –∂–µ–ª–∞–Ω–∏–µ –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è.")
                     failed_match_count +=1
                     break # –ü—Ä–µ–º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥
                else:
                    print("  -> –ù–µ–≤–∞–ª–∏–¥–µ–Ω –æ—Ç–≥–æ–≤–æ—Ä. –ú–æ–ª—è, –≤—ä–≤–µ–¥–∏ Y, N –∏–ª–∏ S.")
            # –ö—Ä–∞–π –Ω–∞ while True: –∑–∞ Y/N/S —Ü–∏–∫—ä–ª–∞ (–æ—Ç–º–µ—Å—Ç–≤–∞–Ω–µ—Ç–æ –µ –Ω–∞–≤—ä—Ç—Ä–µ)
        else:
                # –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–æ –±–ª–∏–∑–∫–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ (—Ç–æ–∑–∏ else –µ –∑–∞ if closest_matches:)
                print(f"  ‚ùå –ù–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞ '{line}' (–Ω–∏—Ç–æ –≤ mapping, –Ω–∏—Ç–æ –±–ª–∏–∑–∫–æ –≤ –±–∞–∑–∞—Ç–∞). –í—ä–≤–µ–¥–∏ —Ä—ä—á–Ω–æ –∫–æ–¥.")
                manual_code = prompt_user("–í—ä–≤–µ–¥–∏ –ø—Ä–∞–≤–∏–ª–Ω–∏—è –∫–æ–¥ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ (–æ—Å—Ç–∞–≤–∏ –ø—Ä–∞–∑–Ω–æ –∑–∞ –ø—Ä–æ–ø—É—Å–∫–∞–Ω–µ):", None, gui_mode=gui_mode)
                if not manual_code:
                    print("  -> –ü—Ä–æ–ø—É—Å–∫–∞–º —Ç–æ–∑–∏ —Ä–µ–¥ –ø–æ –∂–µ–ª–∞–Ω–∏–µ –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è.")
                    failed_match_count +=1
                    break # –ü—Ä–µ–º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥

                if materials_df is None:
                    print("  ‚ö†Ô∏è –ù—è–º–∞ –∑–∞—Ä–µ–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∏ ‚Äì —Ä—ä—á–Ω–∏—è—Ç –∫–æ–¥ –Ω–µ –º–æ–∂–µ –¥–∞ –±—ä–¥–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω.")
                    failed_match_count += 1
                    continue

                result = materials_df[materials_df['–ù–æ–º–µ—Ä'] == manual_code]
                if not result.empty:
                    row_data = result.iloc[0]
                    manual_matched_name = row_data['–ò–º–µ –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª']
                    item_data = {
                        'code': manual_code,
                        'name': manual_matched_name, # –ò–º–µ—Ç–æ –æ—Ç –±–∞–∑–∞—Ç–∞
                        'qty': extract_quantity(line),
                        'purchase_price': row_data['–ü–æ—Å–ª–µ–¥–Ω–∞ –ø–æ–∫—É–ø–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'selling_price': row_data['–ü—Ä–æ–¥–∞–∂–Ω–∞ —Ü–µ–Ω–∞'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'barcode': row_data['–ë–∞—Ä–∫–æ–¥'], # –û—Ç –±–∞–∑–∞—Ç–∞
                        'token': line,
                    }     # <--- –£–í–ï–†–ò –°–ï, –ß–ï –ò –¢–£–ö –ò–ú–ê –°–ö–û–ë–ê!
                    export_items.append(item_data)
                    # –î–æ–±–∞–≤—è–Ω–µ –∫—ä–º mapping —Å –ò–ú–ï–¢–û –û–¢ –ë–ê–ó–ê–¢–ê –∫–∞—Ç–æ –∫–ª—é—á
                    cleaned_line = normalize_line(line)
                    mapping[cleaned_line] = {
                        'code': manual_code,
                        'name': manual_matched_name  # —Ç–æ–≤–∞ –æ—Å—Ç–∞–≤–∞ –∏–º–µ—Ç–æ –æ—Ç –±–∞–∑–∞—Ç–∞
                    }
                    needs_saving = True # –ú–∞—Ä–∫–∏—Ä–∞–º–µ –∑–∞ –∑–∞–ø–∏—Å
                    print(f"  ‚úÖ –†—ä—á–Ω–æ –≤—ä–≤–µ–¥–µ–Ω –∫–æ–¥ '{manual_code}' ({manual_matched_name}). –î–æ–±–∞–≤—è–º –∫—ä–º –µ–∫—Å–ø–æ—Ä—Ç –∏ –∑–∞–ø–∏—Å–≤–∞–º –≤ mapping.")
                    matched_via_manual += 1
                    continue # –ü—Ä–µ–º–∏–Ω–∏ –∫—ä–º —Å–ª–µ–¥–≤–∞—â–∏—è —Ä–µ–¥
                else:
                    print(f"  ‚ùå –ì—Ä–µ—à–∫–∞: –ö–æ–¥ '{manual_code}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω –≤ '{MATERIALS_FILE}'. –û–ø–∏—Ç–∞–π –ø–∞–∫.")
                        # –¶–∏–∫—ä–ª—ä—Ç —â–µ –ø–æ–ø–∏—Ç–∞ –æ—Ç–Ω–æ–≤–æ –∑–∞ Y/n/s
    # –ö—Ä–∞–π –Ω–∞ for line in lines: —Ü–∏–∫—ä–ª–∞ (–æ—Ç–º–µ—Å—Ç–≤–∞–Ω–µ—Ç–æ –µ –Ω–∞–≤—ä–Ω, –ø–æ–¥—Ä–∞–≤–Ω–µ–Ω–æ —Å for)

    # 5. –ó–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ mapping (–∞–∫–æ –∏–º–∞ –ø—Ä–æ–º–µ–Ω–∏) - –¢–æ–∑–∏ –±–ª–æ–∫ –µ –°–õ–ï–î for —Ü–∏–∫—ä–ª–∞ (–ø–æ–¥—Ä–∞–≤–Ω–µ–Ω —Å for)
    if needs_saving:
        save_mapping(mapping)
    else:
        print("\nINFO: –ù—è–º–∞ –ø—Ä–æ–º–µ–Ω–∏ –≤ mapping —Ñ–∞–π–ª–∞.")

    # 6. –ï–∫—Å–ø–æ—Ä—Ç - –¢–æ–∑–∏ –±–ª–æ–∫ –µ –°–õ–ï–î for —Ü–∏–∫—ä–ª–∞ (–ø–æ–¥—Ä–∞–≤–Ω–µ–Ω —Å for)
    if export_items:
        export_to_mistral_format(export_items, export_path)

    else:
        print("\n‚ö†Ô∏è –ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏/–ø–æ—Ç–≤—ä—Ä–¥–µ–Ω–∏ –∞—Ä—Ç–∏–∫—É–ª–∏ –∑–∞ –µ–∫—Å–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ.")

    # 7. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ - –¢–æ–∑–∏ –±–ª–æ–∫ –µ –°–õ–ï–î for —Ü–∏–∫—ä–ª–∞ (–ø–æ–¥—Ä–∞–≤–Ω–µ–Ω —Å for)
    print("\n--- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ ---")
    print(f"–û–±—â–æ —Ä–µ–¥–æ–≤–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {len(lines)}")
    print(f"–ü—Ä–æ–ø—É—Å–Ω–∞—Ç–∏ —Ä–µ–¥–æ–≤–µ (–Ω–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∏): {skipped_lines_count}")
    print(f"–û–±—Ä–∞–±–æ—Ç–µ–Ω–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∏ —Ä–µ–¥–æ–≤–µ: {processed_lines_count}")
    print("-" * 20)
    print(f"–ù–∞–º–µ—Ä–µ–Ω–∏ —á—Ä–µ–∑ mapping.json: {matched_via_mapping}")
    print(f"–ù–∞–º–µ—Ä–µ–Ω–∏ —á—Ä–µ–∑ –±–ª–∏–∑–∫–æ —Å—ä–≤–ø–∞–¥–µ–Ω–∏–µ (–ø–æ—Ç–≤—ä—Ä–¥–µ–Ω–∏): {matched_via_fuzzy}")
    print(f"–ù–∞–º–µ—Ä–µ–Ω–∏ —á—Ä–µ–∑ —Ä—ä—á–Ω–æ –≤—ä–≤–µ–¥–µ–Ω –∫–æ–¥: {matched_via_manual}")
    print(f"–ù–µ—É—Å–ø–µ—à–Ω–∏/–ø—Ä–æ–ø—É—Å–Ω–∞—Ç–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∏ —Ä–µ–¥–æ–≤–µ: {failed_match_count}")
    print("-" * 20)
    print(f"–ê—Ä—Ç–∏–∫—É–ª–∏ –¥–æ–±–∞–≤–µ–Ω–∏ –≤ –µ–∫—Å–ø–æ—Ä—Ç–Ω–∏—è —Ñ–∞–π–ª: {len(export_items)}")
    print("--- –ö—Ä–∞–π ---")
# –ö—Ä–∞–π –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è—Ç–∞ main() - —Ç—É–∫ —Å–≤—ä—Ä—à–≤–∞ –æ—Ç–º–µ—Å—Ç–≤–∞–Ω–µ—Ç–æ –Ω–∞–≤—ä—Ç—Ä–µ –∑–∞ main

    return export_items


# --- –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ --- (–¢–æ–∑–∏ –±–ª–æ–∫ –µ –ò–ó–í–™–ù main(), –±–µ–∑ –æ—Ç–º–µ—Å—Ç–≤–∞–Ω–µ)
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n–ö—Ä–∏—Ç–∏—á–Ω–∞ –≥—Ä–µ—à–∫–∞ –≤ –ø—Ä–æ–≥—Ä–∞–º–∞—Ç–∞: {e}")
        import traceback
        traceback.print_exc() # –û—Ç–ø–µ—á–∞—Ç–≤–∞ –ø—ä–ª–Ω–∏—è traceback –∑–∞ –¥–µ–±—ä–≥
    finally:
        prompt_user("\–ù–∞—Ç–∏—Å–Ω–∏ Enter –∑–∞ –∏–∑—Ö–æ–¥...", gui_mode=False)





